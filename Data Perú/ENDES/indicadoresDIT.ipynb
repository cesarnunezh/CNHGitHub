{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Nacimiento saludable"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32dcc349c2ec919d"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-24T17:11:11.710919400Z",
     "start_time": "2023-11-24T17:11:11.141950300Z"
    }
   },
   "outputs": [],
   "source": [
    "#Librerías\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_34360\\266190699.py:35: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  df = pd.read_stata(f\"rec91_{anio}.dta\", convert_categoricals=True, columns= ['ID1', 'CASEID', 'SREGION', 'S119', 'S108N'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_34360\\266190699.py:37: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  df = pd.read_stata(f\"rec91_{anio}.dta\", convert_categoricals=True, columns= ['id1','caseid','sregion', 's119', 's108n'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_34360\\266190699.py:35: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  df = pd.read_stata(f\"rec91_{anio}.dta\", convert_categoricals=True, columns= ['ID1', 'CASEID', 'SREGION', 'S119', 'S108N'])\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\User\\OneDrive - Universidad del Pacífico\\1. Documentos\\0. Bases de datos\\03. ENDES\\1. Data')\n",
    "\n",
    "# Modulo DIT\n",
    "dit = pd.DataFrame()\n",
    "for anio in range(2019,2023):\n",
    "    df = pd.read_stata(f\"dit_{anio}.dta\", convert_categoricals=True)\n",
    "    df.columns = df.columns.str.lower()\n",
    "    dit= pd.concat([dit,df], ignore_index=True)\n",
    "dit['id1'] = dit['id1'].astype(int)\n",
    "\n",
    "# Modulo REC21\n",
    "rec21 = pd.DataFrame()\n",
    "for anio in range(2019,2023):\n",
    "    try:\n",
    "        df = pd.read_stata(f\"rec21_{anio}.dta\", columns = ['ID1', 'CASEID', 'BIDX', 'B4'])\n",
    "    except:\n",
    "        df = pd.read_stata(f\"rec21_{anio}.dta\", columns = ['id1', 'caseid', 'bidx', 'b4'])\n",
    "    df.columns = df.columns.str.lower()\n",
    "    rec21 = pd.concat([rec21,df], ignore_index=True)\n",
    "\n",
    "# Modulo REC0111\n",
    "rec0111 = pd.DataFrame()\n",
    "for anio in range(2019,2023):\n",
    "    try:\n",
    "        df = pd.read_stata(f\"rec0111_{anio}.dta\", convert_categoricals=True, columns = ['ID1', 'CASEID', 'V001', 'V005', 'V012', 'V022' ,'V024' ,'V025' ,'V149' ,'V190'])\n",
    "    except:\n",
    "        df = pd.read_stata(f\"rec0111_{anio}.dta\", convert_categoricals=True, columns = ['id1','caseid', 'v001', 'v005', 'v012', 'v022' ,'v024' ,'v025' ,'v149' ,'v190'])\n",
    "    df.columns = df.columns.str.lower()\n",
    "    rec0111= pd.concat([rec0111,df], ignore_index=True)\n",
    "\n",
    "# Modulo REC91\n",
    "rec91 = pd.DataFrame()\n",
    "for anio in range(2019, 2023):\n",
    "    try:\n",
    "        df = pd.read_stata(f\"rec91_{anio}.dta\", convert_categoricals=True, columns= ['ID1', 'CASEID', 'SREGION', 'S119', 'S108N'])\n",
    "    except:\n",
    "        df = pd.read_stata(f\"rec91_{anio}.dta\", convert_categoricals=True, columns= ['id1','caseid','sregion', 's119', 's108n'])\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "    # Exclude empty or all-NA columns before concatenation\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    rec91 = pd.concat([rec91, df], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T18:01:45.226414700Z",
     "start_time": "2023-11-24T18:01:43.786647800Z"
    }
   },
   "id": "30843ef145b4e9fe"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# Merging datasets\n",
    "mergedDIT = pd.merge(dit, rec21.loc[:,['id1','caseid', 'bidx', 'b4']], how='inner', on=['id1','caseid', 'bidx'], validate=\"1:1\")\n",
    "mergedDIT = pd.merge(mergedDIT, rec0111.loc[:,['id1','caseid', 'v001', 'v005', 'v012', 'v022' ,'v024' ,'v025' ,'v149' ,'v190']], how='inner', on=['id1','caseid'], validate=\"m:1\")\n",
    "mergedDIT = pd.merge(mergedDIT, rec91.loc[:,['id1','caseid','sregion', 's119', 's108n']], how='inner', on=['id1','caseid'], validate=\"m:1\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T20:45:50.695140700Z",
     "start_time": "2023-11-24T20:45:49.891015300Z"
    }
   },
   "id": "f830677b08cff61"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "# Generando variables de interés\n",
    "mergedDIT['v149_'] = mergedDIT['v149'].array.codes\n",
    "mergedDIT['educa'] = 1  # Initialize with a default value\n",
    "mergedDIT.loc[mergedDIT['v149_'] > 2, 'educa'] = 2\n",
    "mergedDIT.loc[mergedDIT['v149_'] == 5, 'educa'] = 3\n",
    "del mergedDIT['v149_']\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T20:54:39.704288100Z",
     "start_time": "2023-11-24T20:54:39.692273300Z"
    }
   },
   "id": "6d85c6e5a973a70b"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qi478e3\n",
      "Si                     4593\n",
      "No                      608\n",
      "No responde/No sabe       3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(mergedDIT['qi478e3'].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T18:04:47.117953300Z",
     "start_time": "2023-11-24T18:04:47.104571900Z"
    }
   },
   "id": "6d7fb66ee7533de"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Factor de expansion\n",
    "merged_final[\"wt\"] = merged_final[\"v005\"] / 1000000\n",
    "\n",
    "# Generamos la variable EDADM\n",
    "merged_final[\"edadm\"] = merged_final[\"v008\"] - merged_final[\"b3\"]\n",
    "merged_final[\"e_0a35\"] = merged_final[\"edadm\"] < 36\n",
    "merged_final[\"e_0a59\"] = merged_final[\"edadm\"] < 60\n",
    "\n",
    "# Peso al nacer\n",
    "merged_final[\"pesonac\"] = 1\n",
    "merged_final.loc[(merged_final[\"m19\"] > 2499) & (merged_final[\"m19\"] <= 8000) & (merged_final[\"v012\"] > 14), \"pesonac\"] = 2\n",
    "merged_final.loc[merged_final[\"m19\"] == 9996 & (merged_final[\"v012\"] > 14), \"pesonac\"] = 3\n",
    "merged_final.loc[merged_final[\"m19\"] == 9998 & (merged_final[\"v012\"] > 14), \"pesonac\"] = 4\n",
    "\n",
    "# Labels for pesonac\n",
    "labels = {1: \"Menos de 2.5kg\", 2: \">=2.5 kg\", 3: \"No pesados al nacer\", 4: \"No sabe, sin informacion\"}\n",
    "merged_final[\"pesonac\"] = merged_final[\"pesonac\"].map(labels)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31fcdf629ae34596"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Tabulations\n",
    "tab1 = pd.crosstab(merged_final[\"pesonac\"], merged_final[\"e_0a59\"], values=merged_final[\"wt\"], aggfunc=\"sum\")\n",
    "tab2 = pd.crosstab([merged_final[\"v463a\"], merged_final[\"pesonac\"]], merged_final[\"e_0a59\"], values=merged_final[\"wt\"], aggfunc=\"sum\")\n",
    "tab3 = pd.crosstab([merged_final[\"v190\"], merged_final[\"pesonac\"]], merged_final[\"e_0a59\"], values=merged_final[\"wt\"], aggfunc=\"sum\")\n",
    "tab4 = pd.crosstab([merged_final[\"etnia\"], merged_final[\"pesonac\"]], merged_final[\"e_0a59\"], values=merged_final[\"wt\"], aggfunc=\"sum\")\n",
    "tab5 = pd.crosstab([merged_final[\"lmaterna\"], merged_final[\"pesonac\"]], merged_final[\"e_0a59\"], values=merged_final[\"wt\"], aggfunc=\"sum\")\n",
    "tab6 = pd.crosstab([merged_final[\"v025\"], merged_final[\"pesonac\"]], merged_final[\"e_0a59\"], values=merged_final[\"wt\"], aggfunc=\"sum\")\n",
    "tab7 = pd.crosstab([merged_final[\"sregion\"], merged_final[\"pesonac\"]], merged_final[\"e_0a59\"], values=merged_final[\"wt\"], aggfunc=\"sum\")\n",
    "\n",
    "# Tamaño de la niña o niño al nacer\n",
    "merged_final[\"ch_size_birth\"] = pd.cut(merged_final[\"m18\"], bins=[-1, 2, 4, 5, 8, 9], labels=[\"Promedio o mayor\", \"Menor que promedio\", \"Muy pequeño\", \"No sabe/sin información\"], right=False)\n",
    "tab8 = pd.crosstab(merged_final[\"ch_size_birth\"], merged_final[\"e_0a59\"], values=merged_final[\"wt\"], aggfunc=\"sum\")\n",
    "tab9 = pd.crosstab([merged_final[\"v463a\"], merged_final[\"ch_size_birth\"]], merged_final[\"e_0a59\"], values=merged_final[\"wt\"], aggfunc=\"sum\")\n",
    "tab10 = pd.crosstab([merged_final[\"v190\"], merged_final[\"ch_size_birth\"]], merged_final[\"e_0a59\"], values=merged_final[\"wt\"], aggfunc=\"sum\")\n",
    "tab11 = pd.crosstab([merged_final[\"etnia\"], merged_final[\"ch_size_birth\"]], merged_final[\"e_0a59\"], values=merged_final[\"wt\"], aggfunc=\"sum\")\n",
    "tab12 = pd.crosstab([merged_final[\"lmaterna\"], merged_final[\"ch_size_birth\"]], merged_final[\"e_0a59\"], values=merged_final[\"wt\"], aggfunc=\"sum\")\n",
    "tab13 = pd.crosstab([merged_final[\"v025\"], merged_final[\"ch_size_birth\"]], merged_final[\"e_0a59\"], values=merged_final[\"wt\"], aggfunc=\"sum\")\n",
    "tab14 = pd.crosstab([merged_final[\"sregion\"], merged_final[\"ch_size_birth\"]], merged_final[\"e_0a59\"], values=merged_final[\"wt\"], aggfunc=\"sum\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bafb90ea076a7153"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
